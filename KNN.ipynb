{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing Data Science - Tutorial on K-Nearest Neighbors\n",
    "- The k-NN algorithm is a nonparametric approach to classification.\n",
    "- K-NN is an algorithm that can be used when you have a bunch of objects that have been classified or labeled in some way, and other similar objects that haven't gotten classified or labeled yet, and you want a way to automatically label them.\n",
    "- As a classification algorithm, it can be applied where 'linear-regression-with-a-threshold' cannot, such as when the labels do not take a continuous value scale like a credit score.\n",
    "- The intution behind k-NN is to consider the most similar other items defined in terms of their attributes, look at their labels, and give the unassigned item the majority vote. If there's a tie, you randomly select among the labels that have tied for first.\n",
    "\n",
    "**Two Decisions to be made**\n",
    "1. how do you define similarity or closeness?\n",
    "2. how many neighbors should vote? This value is *k*\n",
    "\n",
    "**k-NN process overview**\n",
    "1. Decide on your similarity or distance metric.\n",
    "2. Split the original labeled dataset into training and test data.\n",
    "3. Pick an evaluation metric. (Misclassification rate is a good one.)\n",
    "4. Run k-NN a few times, changing *k* and checking the evaluation measure.\n",
    "5. Optimize *k* by picking the one with the best evaluation measure.\n",
    "6. Once you've chosen *k*, use the same training set and now create a new test set with people's ages and incomes that you have no labels for, and want to predict.\n",
    "\n",
    "**Notable similarity metrics**\n",
    "- Euclidean distance\n",
    "- Cosine similarity\n",
    "- Jaccard distance or similarity (Tanimoto)\n",
    "- Mahalanobis distance\n",
    "- Hamming distance\n",
    "- Manhattan distance\n",
    "\n",
    "In classification, a balance has to be struck between being *sensitive* to the reality of the data (true positive or recall) and being *specific* (true negative) to the classification with respect to the categories of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code tutorial from [here](https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/) \n",
    "- Data: [Iris dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Handle Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(filename, split, trainingSet, testSet):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        # shuffle the dataset\n",
    "        for i in range(5):\n",
    "            random.shuffle(dataset)\n",
    "        for x in range(len(dataset)-1):\n",
    "            for y in range(4):\n",
    "                dataset[x][y]= float(dataset[x][y])\n",
    "            if random.random() < split:\n",
    "                trainingSet.append(dataset[x])\n",
    "            else:\n",
    "                testSet.append(dataset[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet, testSet = [], []\n",
    "loadDataset(\"iris.data\",0.66,trainingSet,testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDistance(instance1, instance2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += pow((instance1[x]-instance2[x]),2)\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 3.4641016151377544\n"
     ]
    }
   ],
   "source": [
    "# distance test\n",
    "data1 = [2,2,2,'a']\n",
    "data2 = [4,4,4,'b']\n",
    "distance = euclideanDistance(data1, data2, 3)\n",
    "print(\"Distance:\",str(distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Neighbors**\n",
    "\n",
    "The `getNeighbors()` function returns *k* most similar neighbors from the training set for a given test instance, using the already defined `euclideanDistance()`function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbors(trainingSet, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance)-1\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = euclideanDistance(testInstance, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.2, 4.1, 1.5, 0.1, 'Iris-setosa']]\n"
     ]
    }
   ],
   "source": [
    "# neighbors test\n",
    "trainSet = [[2,2,2,'a'],[4,4,4,'b']]\n",
    "testInstance = [5,5,5]\n",
    "k=1\n",
    "neighbors = getNeighbors(trainingSet, testInstance, 1)\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Response**\n",
    "\n",
    "Once we have located the most similar neighbors for a test instance, the next task is to devise a predicted response based on those neighbors.\n",
    "We can do this by allowing each neighbor to vote for their class attribute, and take the majority vote as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponseMajorityVote(neighbors):\n",
    "    classVotes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    sortedVotes = sorted(classVotes.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    return sortedVotes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "# majority vote test\n",
    "neighbors = [[1,1,1,'a'],[2,2,2,'a'],[3,3,3,'b']]\n",
    "response = getResponseMajorityVote(neighbors)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Accuracy**\n",
    "\n",
    "We have all teh pieces of the kNN algorithm in place. An important remaining concern is how to evaluate the accuracy of predictions.\n",
    "\n",
    "Below, the `getPredictionAccuracy()` function sums the total correct predictions and returns the accuracy as a percentage of correct classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictionAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "#     print(\"num of predictions:\",len(predictions),\"number correct:\",correct)\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "# accuracy test\n",
    "testSet = [[1,1,1,'a'],[2,2,2,'a'],[3,3,3,'b']]\n",
    "predictions = ['a','a','a']\n",
    "accuracy = getPredictionAccuracy(testSet, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Main - putting it all together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # prepare data\n",
    "    trainingSet = []\n",
    "    testSet = []\n",
    "    split = 0.67\n",
    "    loadDataset(\"iris.data\",split,trainingSet,testSet)\n",
    "    print(\"Training set:\",len(trainingSet))\n",
    "    print(\"Test set:\",len(testSet))\n",
    "    \n",
    "    #generate predictions\n",
    "    predictions = []\n",
    "    k = 1\n",
    "    for x in range(len(testSet)):\n",
    "        neighbors = getNeighbors(trainingSet, testSet[x], k)\n",
    "        result = getResponseMajorityVote(neighbors)\n",
    "        predictions.append(result)\n",
    "        print(\"> predicted=\" + repr(result) + \", actual=\" + repr(testSet[x][-1]))\n",
    "    accuracy = getPredictionAccuracy(testSet, predictions)\n",
    "    print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 99\n",
      "Test set: 50\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-versicolor', actual='Iris-virginica'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-virginica', actual='Iris-versicolor'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-versicolor'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-virginica', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "Accuracy: 92.0\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
